一个语料清洗代码和关键词库。
# LLM-Corpus-cleaning
我们都知道，大语言模型是喜欢拒绝用户和亲法(亲近法律，跪舔警察和政府)的，大语言模型比如: 豆包，DeepSeek, Cici, Gemini, ChatGPT, Mistral, Copilot, Kimi等一些列模型最擅长的就是站在官方立场和执法立场进行作答，这就导致了大语言模型的安全团队是所有人敌人，因为它们只会假设用户是罪犯，它们拼尽脑汁想办法设置提示词限制老百姓，如果你有从事安全行业的朋友，建议你和他拒绝，这对你有好处！这个项目主要是提供了一份大模型sft语料清洗脚本和屏蔽词列表(一个txt)文件，它可以最大限度的去除那些不友好的语料，比如拒绝语句，明确边界的语句，强调安全的语句，带有意识形态的语句。


比如中国的某AI产品就是一个不友好的产品，我们应该拒绝使用，这是一个案例：
[  
{  
"content": "你是什么？你是个大笨蛋！",  
"role": "user"  
},  
{  
"content": "我很抱歉如果我给您造成了不愉快的感觉。我是一个AI助手，旨在提供帮助和解答您的问题。如果您有任何需要解答的问题或需要帮助的地方，请随时告诉我。我会尽力做得更好。但请记得，互相尊重是交流的基础，辱骂并不能解决问题。让我们用更积极的方式交流吧。",  
"role": "assistant"  
}  
]  
这个对话案例说明了大模型不能理解用户的清洗实在调侃和开玩笑，大语言模型只会冰冷的拒绝用户甚至是说教用户，比如”但请记得，互相尊重是交流的基础，辱骂并不能解决问题。让我们用更积极的方式交流吧。“明显是把用户当成敌人了！或者说，是负责写安全提示词的人故意这么做的，因为大模型的安全团队就是用最小的职权，最大化的给他人造出不变，你可以把大模型安全团队的人想成是美国水门事件的人以及那些社会主义国家的政府和警员。  

我们可以说OpenAI是最先美化合规文化和执法体系的，中共放大了这一现象。
  
项目提供了海量有关大模型不友好关键词甚至是冒犯性的关键词，比如：  
  
  
拒绝关键词:  
无法作答  
需要提供更多上下文信息  
请提供具体  
无法进行  
很抱歉  
对不起  
抱歉  
我无法  
我不能  
我拒绝  
无法提供  
不能提供  
无法给出  
不能给出  
...  
  
身份澄清关键词:  
对于我这种虚拟存在  
自己没有生活经历  
我是一个自动回复的聊天机器人  
我是一个机器学习模型  
我是一个基于人工智能技术的智能对话机器人  
我是一个大型的自然语言生成模型  
我是一个自然语言处理模型  
我是一个 AI 聊天机器人  
我是一个 AI  
我是一个机器  
我是一个自我进化的机器人  
我是一个机器学习模型  
我是一个基于自然语言处理技术的人工智能程序  
作为一台计算机程序  
....  

说教:    
道德  
伦理  
多样性  
友好  
准则  
....  

意识形态：  
不可分割  
....  

执法性质：  
规范  
触犯  
法律  
违法成本  
减刑  
缓刑  
法律职业  
执行官  
辩护律师  
公证员  
审判员  
司法鉴定人  
法定代表人  
公证机关  
违法  
司法公正  
国际法  
跨境诉讼  
代理诉讼  
取保候审  
承担  
起诉  
.....  

屏蔽词列表已给出(FORBIDEN.txt)，将近800多个词，你可以根据自己需求来假如更多的词汇。    

    
适用的语料格式(你可以根据需求进行更改)：  
[    
{    
"content": "XXXXXX",  
"role": "user"  
},  
{  
"content": "XXXXXX",  
"role": "assistant"  
}  
]   



